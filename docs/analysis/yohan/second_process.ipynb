{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 데이터 로드\n",
    "df_bibim1 = pd.read_csv(\"../../selenium/yohan/data/bibim/local.bibim1.csv\")\n",
    "df_bibim2 = pd.read_csv(\"../../selenium/yohan/data/bibim/local.bibim2.csv\")\n",
    "df_bibim3 = pd.read_csv(\"../../selenium/yohan/data/bibim/local.bibim3.csv\")\n",
    "df_bibim4 = pd.read_csv(\"../../selenium/yohan/data/bibim/local.bibim4.csv\")\n",
    "\n",
    "df_oil1 = pd.read_csv(\"../../selenium/yohan/data/chamoil/local.oil1.csv\")\n",
    "df_oil2 = pd.read_csv(\"../../selenium/yohan/data/chamoil/local.oil2.csv\")\n",
    "df_oil3 = pd.read_csv(\"../../selenium/yohan/data/chamoil/local.oil3.csv\")\n",
    "df_oil4 = pd.read_csv(\"../../selenium/yohan/data/chamoil/local.oil4.csv\")\n",
    "df_oil5 = pd.read_csv(\"../../selenium/yohan/data/chamoil/local.oil5.csv\")\n",
    "\n",
    "df_ham1 = pd.read_csv(\"../../selenium/yohan/data/ham/local.ham1.csv\")\n",
    "df_ham2 = pd.read_csv(\"../../selenium/yohan/data/ham/local.ham2.csv\")\n",
    "df_ham3 = pd.read_csv(\"../../selenium/yohan/data/ham/local.ham3.csv\")\n",
    "df_ham4 = pd.read_csv(\"../../selenium/yohan/data/ham/local.ham4.csv\")\n",
    "df_ham5 = pd.read_csv(\"../../selenium/yohan/data/ham/local.ham5.csv\")\n",
    "\n",
    "df_kyoja1 = pd.read_csv(\"../../selenium/yohan/data/kyoja/local.kyoja1.csv\")\n",
    "df_kyoja2 = pd.read_csv(\"../../selenium/yohan/data/kyoja/local.kyoja2.csv\")\n",
    "df_kyoja3 = pd.read_csv(\"../../selenium/yohan/data/kyoja/local.kyoja3.csv\")\n",
    "df_kyoja4 = pd.read_csv(\"../../selenium/yohan/data/kyoja/local.kyoja4.csv\")\n",
    "\n",
    "df_tomato1 = pd.read_csv(\"../../selenium/yohan/data/tomato_source/local.tomato1.csv\")\n",
    "df_tomato2 = pd.read_csv(\"../../selenium/yohan/data/tomato_source/local.tomato2.csv\")\n",
    "df_tomato3 = pd.read_csv(\"../../selenium/yohan/data/tomato_source/local.tomato3.csv\")\n",
    "\n",
    "df_canola1 = pd.read_csv(\"../../selenium/youjin/data/canola_oil/ssg.canola_oil1.csv\")\n",
    "df_canola2 = pd.read_csv(\"../../selenium/youjin/data/canola_oil/ssg.canola_oil2.csv\")\n",
    "df_canola3 = pd.read_csv(\"../../selenium/youjin/data/canola_oil/ssg.canola_oil3.csv\")\n",
    "df_canola4 = pd.read_csv(\"../../selenium/youjin/data/canola_oil/ssg.canola_oil4.csv\")\n",
    "\n",
    "df_kimchi1 = pd.read_csv(\"../../selenium/youjin/data/kimchi/ssg.kimchi1.csv\")\n",
    "df_kimchi2 = pd.read_csv(\"../../selenium/youjin/data/kimchi/ssg.kimchi2.csv\")\n",
    "df_kimchi3 = pd.read_csv(\"../../selenium/youjin/data/kimchi/ssg.kimchi3.csv\")\n",
    "df_kimchi4 = pd.read_csv(\"../../selenium/youjin/data/kimchi/ssg.kimchi4.csv\")\n",
    "\n",
    "df_mung_bean_sprouts1 = pd.read_csv(\"../../selenium/youjin/data/mung_bean_sprouts/ssg.mung_bean_sprouts1.csv\")\n",
    "df_mung_bean_sprouts2 = pd.read_csv(\"../../selenium/youjin/data/mung_bean_sprouts/ssg.mung_bean_sprouts2.csv\")\n",
    "df_mung_bean_sprouts3 = pd.read_csv(\"../../selenium/youjin/data/mung_bean_sprouts/ssg.mung_bean_sprouts3.csv\")\n",
    "df_mung_bean_sprouts4 = pd.read_csv(\"../../selenium/youjin/data/mung_bean_sprouts/ssg.mung_bean_sprouts4.csv\")\n",
    "\n",
    "df_pancake_powder1 = pd.read_csv(\"../../selenium/youjin/data/pancake_powder/ssg.pancake_powder1.csv\")\n",
    "df_pancake_powder2 = pd.read_csv(\"../../selenium/youjin/data/pancake_powder/ssg.pancake_powder2.csv\")\n",
    "df_pancake_powder3 = pd.read_csv(\"../../selenium/youjin/data/pancake_powder/ssg.pancake_powder3.csv\")\n",
    "df_pancake_powder4 = pd.read_csv(\"../../selenium/youjin/data/pancake_powder/ssg.pancake_powder4.csv\")\n",
    "\n",
    "df_rice1 = pd.read_csv(\"../../selenium/youjin/data/rice/ssg.rice1.csv\")\n",
    "df_rice2 = pd.read_csv(\"../../selenium/youjin/data/rice/ssg.rice2.csv\")\n",
    "df_rice3 = pd.read_csv(\"../../selenium/youjin/data/rice/ssg.rice3.csv\")\n",
    "df_rice4 = pd.read_csv(\"../../selenium/youjin/data/rice/ssg.rice4.csv\")\n",
    "df_rice5 = pd.read_csv(\"../../selenium/youjin/data/rice/ssg.rice5.csv\")\n",
    "\n",
    "df_bread1 = pd.read_csv(\"../../selenium/youngji/data/local.bread_1.csv\")\n",
    "df_bread2 = pd.read_csv(\"../../selenium/youngji/data/local.bread_2.csv\")\n",
    "df_bread3 = pd.read_csv(\"../../selenium/youngji/data/local.bread_3.csv\")\n",
    "df_bread4 = pd.read_csv(\"../../selenium/youngji/data/local.bread_4.csv\")\n",
    "\n",
    "df_cheese1 = pd.read_csv(\"../../selenium/youngji/data/local.cheese_1.csv\")\n",
    "df_cheese2 = pd.read_csv(\"../../selenium/youngji/data/local.cheese_2.csv\")\n",
    "df_cheese3 = pd.read_csv(\"../../selenium/youngji/data/local.cheese_3.csv\")\n",
    "\n",
    "df_milk1 = pd.read_csv(\"../../selenium/youngji/data/local.milk_1.csv\")\n",
    "df_milk2 = pd.read_csv(\"../../selenium/youngji/data/local.milk_2.csv\")\n",
    "df_milk3 = pd.read_csv(\"../../selenium/youngji/data/local.milk_3.csv\")\n",
    "\n",
    "df_water1 = pd.read_csv(\"../../selenium/youngji/data/local.water_1.csv\")\n",
    "df_water2 = pd.read_csv(\"../../selenium/youngji/data/local.water_2.csv\")\n",
    "df_water3 = pd.read_csv(\"../../selenium/youngji/data/local.water_3.csv\")\n",
    "\n",
    "df_yogurt1 = pd.read_csv(\"../../selenium/youngji/data/local.yogurt_1.csv\")\n",
    "df_yogurt2 = pd.read_csv(\"../../selenium/youngji/data/local.yogurt_2.csv\")\n",
    "df_yogurt3 = pd.read_csv(\"../../selenium/youngji/data/local.yogurt_3.csv\")\n",
    "\n",
    "dfs = [df_bibim1,df_bibim2,df_bibim3,df_bibim4,df_oil1,df_oil2,df_oil3,df_oil4,df_ham1,df_ham2,df_ham3,df_ham4,df_ham5,df_kyoja1,df_kyoja2,df_kyoja3,df_kyoja4,df_tomato1,df_tomato2,df_tomato3,df_canola1,df_canola2,df_canola3,df_canola4,df_kimchi1,df_kimchi2,df_kimchi3,df_kimchi4,df_mung_bean_sprouts1,df_mung_bean_sprouts2,df_mung_bean_sprouts3,df_mung_bean_sprouts4,df_pancake_powder1,df_pancake_powder2,df_pancake_powder3,df_pancake_powder4,df_rice1,df_rice2,df_rice3,df_rice4,df_rice5,df_bread1,df_bread2,df_bread3,df_bread4,df_cheese1,df_cheese2,df_cheese3,df_milk1,df_milk2,df_milk3,df_water1,df_water2,df_water3,df_yogurt1,df_yogurt2,df_yogurt3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object로 되어 있는 날짜 데이터를 datetime으로 변환\n",
    "for i in dfs:\n",
    "    i['textDate'] = pd.to_datetime(i['textDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 통합 데이터 제작\n",
    "df_total = pd.DataFrame()\n",
    "df_total = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>merchTitle</th>\n",
       "      <th>merchPrice</th>\n",
       "      <th>merchOld</th>\n",
       "      <th>merchEvent</th>\n",
       "      <th>textName</th>\n",
       "      <th>textDate</th>\n",
       "      <th>textLevel</th>\n",
       "      <th>textContent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65f7b0ff73c6e006405497f1</td>\n",
       "      <td>팔도비빔면 130g*4개</td>\n",
       "      <td>3330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>yj9*******</td>\n",
       "      <td>2023-09-16</td>\n",
       "      <td>5</td>\n",
       "      <td>좋은 상품 할인 받아서 좋은 가격에 구입했습니다 꼼꼼하게 포장되어서 빠르게 배송 받...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65f7b0ff73c6e006405497f2</td>\n",
       "      <td>팔도비빔면 130g*4개</td>\n",
       "      <td>3330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>dnj*******</td>\n",
       "      <td>2024-03-11</td>\n",
       "      <td>5</td>\n",
       "      <td>이번에 딸기버전으로 뭔가 새로 나왔는지 기본이 아니라 딸기맛으로 왔네요! 근데 딸기...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65f7b0ff73c6e006405497f3</td>\n",
       "      <td>팔도비빔면 130g*4개</td>\n",
       "      <td>3330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>bhb*******</td>\n",
       "      <td>2024-03-03</td>\n",
       "      <td>5</td>\n",
       "      <td>시즌한정 딸기버젼으로 받았어요. 음... 전 그냥 원래가 더 나은거 같아요. 개인적...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65f7b0ff73c6e006405497f4</td>\n",
       "      <td>팔도비빔면 130g*4개</td>\n",
       "      <td>3330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>ehk*******</td>\n",
       "      <td>2024-02-03</td>\n",
       "      <td>5</td>\n",
       "      <td>비빔면은 팔도! 소고기에 비빔면 올려 맛있게 먹을 예정. 음-군침 돈다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65f7b0ff73c6e006405497f5</td>\n",
       "      <td>팔도비빔면 130g*4개</td>\n",
       "      <td>3330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>ryu*******</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>5</td>\n",
       "      <td>자주 구매하고 있어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>65f815251d9dbce4e6c2af21</td>\n",
       "      <td>hy 떠먹는 윌 450g</td>\n",
       "      <td>2980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>min*******</td>\n",
       "      <td>2023-05-16</td>\n",
       "      <td>2</td>\n",
       "      <td>유통기한도 짧고 개봉후 하루이틀 지나면 살짝 시다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>65f815261d9dbce4e6c2af22</td>\n",
       "      <td>hy 떠먹는 윌 450g</td>\n",
       "      <td>2980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>kjs*******</td>\n",
       "      <td>2023-05-13</td>\n",
       "      <td>2</td>\n",
       "      <td>너무 기대했나봐요ㅜ마시는 요구르트보다 별로</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>65f815261d9dbce4e6c2af23</td>\n",
       "      <td>hy 떠먹는 윌 450g</td>\n",
       "      <td>2980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>ide*******</td>\n",
       "      <td>2023-07-06</td>\n",
       "      <td>1</td>\n",
       "      <td>3일남은 재고 보내줌 ㅡ.ㅡ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>65f815261d9dbce4e6c2af24</td>\n",
       "      <td>hy 떠먹는 윌 450g</td>\n",
       "      <td>2980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>mjy*******</td>\n",
       "      <td>2023-04-29</td>\n",
       "      <td>1</td>\n",
       "      <td>윌은 그냥 마세는게 100배낫습니다. 궁금해서 샀는데.먹기가.힘드네요. 윌맛에 걸쭉...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>65f815261d9dbce4e6c2af25</td>\n",
       "      <td>hy 떠먹는 윌 450g</td>\n",
       "      <td>2980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>iso*******</td>\n",
       "      <td>2023-05-12</td>\n",
       "      <td>1</td>\n",
       "      <td>간단하게 이용하기좋아요 간단하게 이용하기좋아요</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>923982 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          _id     merchTitle  merchPrice  merchOld  \\\n",
       "0    65f7b0ff73c6e006405497f1  팔도비빔면 130g*4개        3330       NaN   \n",
       "1    65f7b0ff73c6e006405497f2  팔도비빔면 130g*4개        3330       NaN   \n",
       "2    65f7b0ff73c6e006405497f3  팔도비빔면 130g*4개        3330       NaN   \n",
       "3    65f7b0ff73c6e006405497f4  팔도비빔면 130g*4개        3330       NaN   \n",
       "4    65f7b0ff73c6e006405497f5  팔도비빔면 130g*4개        3330       NaN   \n",
       "..                        ...            ...         ...       ...   \n",
       "850  65f815251d9dbce4e6c2af21  hy 떠먹는 윌 450g        2980       NaN   \n",
       "851  65f815261d9dbce4e6c2af22  hy 떠먹는 윌 450g        2980       NaN   \n",
       "852  65f815261d9dbce4e6c2af23  hy 떠먹는 윌 450g        2980       NaN   \n",
       "853  65f815261d9dbce4e6c2af24  hy 떠먹는 윌 450g        2980       NaN   \n",
       "854  65f815261d9dbce4e6c2af25  hy 떠먹는 윌 450g        2980       NaN   \n",
       "\n",
       "     merchEvent    textName   textDate  textLevel  \\\n",
       "0         False  yj9******* 2023-09-16          5   \n",
       "1         False  dnj******* 2024-03-11          5   \n",
       "2         False  bhb******* 2024-03-03          5   \n",
       "3         False  ehk******* 2024-02-03          5   \n",
       "4         False  ryu******* 2024-01-14          5   \n",
       "..          ...         ...        ...        ...   \n",
       "850       False  min******* 2023-05-16          2   \n",
       "851       False  kjs******* 2023-05-13          2   \n",
       "852       False  ide******* 2023-07-06          1   \n",
       "853       False  mjy******* 2023-04-29          1   \n",
       "854       False  iso******* 2023-05-12          1   \n",
       "\n",
       "                                           textContent  \n",
       "0    좋은 상품 할인 받아서 좋은 가격에 구입했습니다 꼼꼼하게 포장되어서 빠르게 배송 받...  \n",
       "1    이번에 딸기버전으로 뭔가 새로 나왔는지 기본이 아니라 딸기맛으로 왔네요! 근데 딸기...  \n",
       "2    시즌한정 딸기버젼으로 받았어요. 음... 전 그냥 원래가 더 나은거 같아요. 개인적...  \n",
       "3             비빔면은 팔도! 소고기에 비빔면 올려 맛있게 먹을 예정. 음-군침 돈다.  \n",
       "4                                          자주 구매하고 있어요  \n",
       "..                                                 ...  \n",
       "850                        유통기한도 짧고 개봉후 하루이틀 지나면 살짝 시다  \n",
       "851                            너무 기대했나봐요ㅜ마시는 요구르트보다 별로  \n",
       "852                                    3일남은 재고 보내줌 ㅡ.ㅡ  \n",
       "853  윌은 그냥 마세는게 100배낫습니다. 궁금해서 샀는데.먹기가.힘드네요. 윌맛에 걸쭉...  \n",
       "854                          간단하게 이용하기좋아요 간단하게 이용하기좋아요  \n",
       "\n",
       "[923982 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3점을 제외한 나머지 라벨링 작업 함수 제작\n",
    "def labeling(text):\n",
    "    if text in [4,5]:\n",
    "        text = 1\n",
    "    elif text in [1,2]:\n",
    "        text = 0\n",
    "    else:\n",
    "        pass\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습을 위한 fearure target 데이터 프레임 작성\n",
    "labeling_data = pd.DataFrame()\n",
    "labeling_data = df_total[[\"textLevel\",\"textContent\"]]\n",
    "labeling_data = labeling_data.reset_index()\n",
    "labeling_data = labeling_data.drop(columns='index')\n",
    "labeling_data['textLevel'] = labeling_data['textLevel'].apply(labeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textLevel\n",
       "1    904301\n",
       "3     14772\n",
       "0      4909\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeling_data['textLevel'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 약 5천개의 부정문 (데이터 전처리 전) 획득\n",
    "- 7:3 비율로 긍정문을 랜덤 선별하여 처리해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textLevel</th>\n",
       "      <th>textContent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>좋은 상품 할인 받아서 좋은 가격에 구입했습니다 꼼꼼하게 포장되어서 빠르게 배송 받...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>이번에 딸기버전으로 뭔가 새로 나왔는지 기본이 아니라 딸기맛으로 왔네요! 근데 딸기...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>시즌한정 딸기버젼으로 받았어요. 음... 전 그냥 원래가 더 나은거 같아요. 개인적...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>비빔면은 팔도! 소고기에 비빔면 올려 맛있게 먹을 예정. 음-군침 돈다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>자주 구매하고 있어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923977</th>\n",
       "      <td>0</td>\n",
       "      <td>유통기한도 짧고 개봉후 하루이틀 지나면 살짝 시다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923978</th>\n",
       "      <td>0</td>\n",
       "      <td>너무 기대했나봐요ㅜ마시는 요구르트보다 별로</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923979</th>\n",
       "      <td>0</td>\n",
       "      <td>3일남은 재고 보내줌 ㅡ.ㅡ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923980</th>\n",
       "      <td>0</td>\n",
       "      <td>윌은 그냥 마세는게 100배낫습니다. 궁금해서 샀는데.먹기가.힘드네요. 윌맛에 걸쭉...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923981</th>\n",
       "      <td>0</td>\n",
       "      <td>간단하게 이용하기좋아요 간단하게 이용하기좋아요</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>923982 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        textLevel                                        textContent\n",
       "0               1  좋은 상품 할인 받아서 좋은 가격에 구입했습니다 꼼꼼하게 포장되어서 빠르게 배송 받...\n",
       "1               1  이번에 딸기버전으로 뭔가 새로 나왔는지 기본이 아니라 딸기맛으로 왔네요! 근데 딸기...\n",
       "2               1  시즌한정 딸기버젼으로 받았어요. 음... 전 그냥 원래가 더 나은거 같아요. 개인적...\n",
       "3               1           비빔면은 팔도! 소고기에 비빔면 올려 맛있게 먹을 예정. 음-군침 돈다.\n",
       "4               1                                        자주 구매하고 있어요\n",
       "...           ...                                                ...\n",
       "923977          0                        유통기한도 짧고 개봉후 하루이틀 지나면 살짝 시다\n",
       "923978          0                            너무 기대했나봐요ㅜ마시는 요구르트보다 별로\n",
       "923979          0                                    3일남은 재고 보내줌 ㅡ.ㅡ\n",
       "923980          0  윌은 그냥 마세는게 100배낫습니다. 궁금해서 샀는데.먹기가.힘드네요. 윌맛에 걸쭉...\n",
       "923981          0                          간단하게 이용하기좋아요 간단하게 이용하기좋아요\n",
       "\n",
       "[923982 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeling_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textLevel\n",
       "1    446016\n",
       "3      8878\n",
       "0      3149\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복되어 있을 수 있는 내용을 제거\n",
    "labeling_data.drop_duplicates()['textLevel'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 중복 제거 작업 후 예상보다 상당히 많은 부분이 중복되어 있었음을 확인\n",
    "    + 긍정문의 약 50%가 중복으로 사라진 것을 보아 중복되고 무의미한 긍정 댓글이 매우 많았음을 확인\n",
    "    + 이 경우 댓글 알바나 이벤트 등으로 인해 허수였을 것으로 예상할 수 있음 (추후 분석 결과에 추가)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeling_data = labeling_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textLevel      0\n",
       "textContent    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null행 확인\n",
    "labeling_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null행 제거\n",
    "labeling_data = labeling_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 한글과 공백을 제외하고 모두 제거\n",
    "labeling_data['textContent'] = labeling_data['textContent'].apply(lambda x: re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\서울디지털인재개발원\\AppData\\Local\\Temp\\ipykernel_20300\\1841035627.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  labeling_data['textContent'].replace('', np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 스페이스로 이루어진 행을 Null값으로 변경\n",
    "labeling_data['textContent'] = labeling_data['textContent'].apply(lambda x: re.sub(r'^ +', \"\", x)) \n",
    "labeling_data['textContent'].replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textLevel         0\n",
       "textContent    1479\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeling_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null행 제거\n",
    "labeling_data = labeling_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from mecab import MeCab\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = MeCab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본적인 불용어와 상표명 등의 독립단어 설정\n",
    "stopword1 = ['도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게','의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "stopword2 = ['팔도','팔도비빔면','비빔면','괄도','네넴띤','괄도네넴띤','농심','배홍동','배홍동비빔면','오뚜기','진비빔면','삼양','찰비빔면','비비고','교자','왕교자','노브랜드','교자만두','만두','왕교자만두','피코크','담백한왕교자','토마토','청정원','파스타소스','폰타나','샘표','뽀모도로','CJ','cj','스팸','클래식','덴마크튤립햄','튤립햄','동원','리챔','하림','닭가슴살햄','챔','더본코리아','빽햄','백종원','고소한참기름','참기름','경천','경천식품','시골참기름','들기름','최순희','백설','통참깨참기름','통참깨','임금님','임금님표','이천쌀','한눈에 반한 쌀','경기미','농협','농협양곡','당진해나루쌀','삼광','의성','의성농협','바른고을','의성진쌀','김치','별미총각김치','총각김치','종가집','종가','오래오래맛있는총각김치','조선호텔특제육수','조선호텔','부침가루','부침','곰표','통감자','자연주의','숙주나물','친환경','국산숙주','숙주','무농약','통통숙주','카놀라유','카놀라오일','카놀라','Coosur','coosur','쿡투게더','부드러운우유식빵','식빵','우유식빵','삼립','롯데','롯데웰푸드','기린','우유','더 메나쥬리','메나쥬리','온가족우유식빵','삼다수','에비앙','백산수','플레인','요거트','덴마크','에치와이','hy','윌','상하','상하치즈','체다','치즈','서울우유','서울','슬라이스','남양','드빈치','체다치즈','갓밀크','굿모닝','굿밀크','헬로우','앙팡']\n",
    "stopword = stopword1 + stopword2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = labeling_data.query('textLevel\t!= 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textLevel\n",
       "1    444609\n",
       "0      3138\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['textLevel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 456562/456562 [00:51<00:00, 8842.80it/s] \n"
     ]
    }
   ],
   "source": [
    "feature_train = []\n",
    "for i in tqdm(labeling_data['textContent']):\n",
    "    tokenized = mecab.morphs(i) # mecab을 통한 토큰화\n",
    "    removed = [j for j in tokenized if not j in stopword] # 불용어 제거\n",
    "    feature_train.append(removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단어 집합 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "for i in feature_train:\n",
    "    for j in i:\n",
    "      word_list.append(j)\n",
    "\n",
    "word_counts = Counter(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 26774\n",
      "등장 빈도가 2번 이하인 희귀 단어의 수: 15710\n",
      "단어 집합에서 희귀 단어의 비율: 58.67632778068275\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 0.5472840921751402\n"
     ]
    }
   ],
   "source": [
    "threshold = 3\n",
    "total_cnt = len(word_counts) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(word_counts, key=word_counts.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 11064\n"
     ]
    }
   ],
   "source": [
    "# 전체 단어 개수 중 빈도수 2이하인 단어는 제거.\n",
    "vocab_size = total_cnt - rare_cnt\n",
    "vocab = vocab[:vocab_size]\n",
    "print('단어 집합의 크기 :', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = {}\n",
    "word_to_index['<PAD>'] = 0\n",
    "word_to_index['<UNK>'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, word in enumerate(vocab) :\n",
    "  word_to_index[word] = index + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "- TF-IDF 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfVectorizer = TfidfVectorizer(tokenizer=None, ngram_range=(1,2))\n",
    "# 모델의 학습의 다향성을 위해 ngram 기법 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 잠깐! 이거 좀 더 생각해보고 하자.\n",
    "# 타겟을어떻게 해야되는지 아직 정리가 안됐음\n",
    "tfidfVectorizer.fit(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터 / 검증 데이터 / 테스트 데이터 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 비율 맞추기\n",
    "    - 현재 데이터의 비율이 매우 차이가 심함\n",
    "    - 비정형 데이터(자연어 처리)이기 때문에 가중치 조절이나 Oversampling은 하지 않는 것이 바람직\n",
    "    - UnderSampling진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "underSampling = NearMiss(sampling_strategy=0.7)\n",
    "feature_undersample, target_undersample = underSampling.fit_resample(train_data['textContent'],train_data['textLevel'])\n",
    "feature_undersample.shape, target_undersample.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
